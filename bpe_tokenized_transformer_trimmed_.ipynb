{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import einops\n",
    "from tokenizers import CharBPETokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import huggingface char-bpe tokenizer\n",
    "en_tokenizer, de_tokenizer = CharBPETokenizer(), CharBPETokenizer()\n",
    "\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "en_tokenizer.add_special_tokens(special_symbols)\n",
    "de_tokenizer.add_special_tokens(special_symbols)\n",
    "\n",
    "# Train tokenizers\n",
    "train_iter, test_iter, valid_iter = Multi30k(language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "\n",
    "de_data, en_data = (list(zip(*train_iter)))\n",
    "en_tokenizer.train_from_iterator(iterator=en_data)\n",
    "de_tokenizer.train_from_iterator(iterator=de_data)\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = tuple(en_tokenizer.encode(x).ids[0] for x in special_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=11, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer.encode(en_data[0])#.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform_en = lambda x : torch.tensor([BOS_IDX] + en_tokenizer.encode(x.rstrip(\"\\n\")).ids + [EOS_IDX])\n",
    "text_transform_de = lambda x : torch.tensor([BOS_IDX] + de_tokenizer.encode(x.rstrip(\"\\n\")).ids + [EOS_IDX])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor(list(train_iter), dtype=torch.StringType)\n",
    "# type(train_iter)\n",
    "# (list(zip(*train_iter)))[0][9]\n",
    "# en_data, de_data = (list(zip(*train_iter)))\n",
    "# de_data_tokenized, en_data_tokenized = \n",
    "# map(lambda x : (x[0], x[1]), train_iter)#list(map(text_transform_de, de_data)), list(map(text_transform_de, de_data))\n",
    "# # de_data_tokenized\n",
    "# tokenized_multik3 = list(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardingFilterIterDataPipe"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(tokenized_multik3), len(list(train_iter)), type(train_iter)\n",
    "# torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(tokenized_multik3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter)))\n",
    "tokenized_train_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter))\n",
    "tokenized_test_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), test_iter))\n",
    "tokenized_valid_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), valid_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(tokenized_train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Position encoding\"\"\"\n",
    "class PositionEncoding2(nn.Module):\n",
    "    def __init__(self, d_embed):\n",
    "        super(PositionEncoding2, self).__init__()\n",
    "        self.d_embed = d_embed\n",
    "\n",
    "    def get_position_encoding(self, seq_len):\n",
    "        encoding = torch.zeros((seq_len, self.d_embed))\n",
    "        dimensions = torch.arange(0, self.d_embed//2)\n",
    "        timesteps = torch.arange(0, seq_len)\n",
    "\n",
    "        encoding[:, 0::2] = torch.sin(torch.einsum('i,j -> ji', 1/(10000**(2*dimensions/self.d_embed)), timesteps))\n",
    "        encoding[:, 1::2] = torch.cos(torch.einsum('i,j -> ji', 1/(10000**(2*dimensions/self.d_embed)), timesteps))\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        pos_encoding = self.get_position_encoding(seq_len=inp.shape[-2])\n",
    "        return inp + pos_encoding # + dropout ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Multihead attention\"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, n_heads):\n",
    "        super().__init__()#MultiheadAttention)\n",
    "        self.d_hidden=d_hidden\n",
    "        self.n_heads = n_heads\n",
    "        self.W_q = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden//n_heads)))\n",
    "        )\n",
    "        self.W_k = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden//n_heads)))\n",
    "        )\n",
    "        self.W_v = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden//n_heads)))\n",
    "        )\n",
    "\n",
    "        self.W_o = nn.Linear(in_features=d_hidden, out_features=d_model, bias=False)\n",
    "\n",
    "    def forward(self, q, k, v, get_attn_scores=False, mask=None, is_causal=False):\n",
    "        mask_shape = (q.shape[-2], k.shape[-2]) \n",
    "        print(\"mask shape: \", mask_shape)\n",
    "        mask = mask if mask else (self.causal_mask(self.n_heads, mask_shape) if is_causal else self.empty_mask(self.n_heads, mask_shape))\n",
    "\n",
    "        # Compute Q, K, V (matrix multiplication, batched along heads)\n",
    "        q = einops.einsum(self.W_q, q, 'h d_model d_h, b T d_model -> b h  T d_h') # T is timesteps (sequence length)\n",
    "        k = einops.einsum(self.W_k, k, 'h d_model d_h, b T d_model -> b h  T d_h')\n",
    "        v = einops.einsum(self.W_v, v, 'h d_model d_h, b T d_model -> b h  T d_h')\n",
    "\n",
    "        print(\"q_shape: \", q.shape)\n",
    "        print(\"k_shape: \", k.shape)\n",
    "\n",
    "        attn_scores = torch.softmax(\n",
    "            einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(self.d_hidden//self.n_heads) + mask,#torch.FloatTensor(self.d_hidden//8)),\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "        attn_head_outs = einops.einsum(attn_scores, v, '... T_out T_in, ... T_in d_h -> ... T_out d_h')\n",
    "        # print(attn_head_outs.shape)\n",
    "        # print(attn_scores, \"mask: \", mask)\n",
    "        # print(\"mask: \", mask)\n",
    "        concatted_outs = einops.rearrange(attn_head_outs, 'b h T_out d_h -> b T_out (h d_h)')\n",
    "        concatted_outs = self.W_o(concatted_outs)\n",
    "\n",
    "        return (concatted_outs, attn_scores) if get_attn_scores else concatted_outs\n",
    "    \n",
    "    @classmethod\n",
    "    def causal_mask(cls, n_heads, mask_shape):\n",
    "        return einops.repeat(\n",
    "            torch.triu(\n",
    "                torch.fill(torch.zeros(mask_shape),  -torch.inf),\n",
    "                diagonal=1\n",
    "                )\n",
    "            , pattern='... -> k ...', k=n_heads\n",
    "            )\n",
    "    \n",
    "    @classmethod\n",
    "    def empty_mask(cls, n_heads, mask_shape):\n",
    "        return einops.repeat(\n",
    "            torch.zeros(mask_shape) , pattern='... -> k ...', k=n_heads\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model=512, d_ff=2048):\n",
    "        super(PosWiseFeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # FFN(x) = max(0, xW1 + b1)W2 + b2 ; f(x) = max(0, x) is relu\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder and Decoder\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, num_heads, d_ff, dropout=0, N_layers=6):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model=d_model, d_hidden=d_hidden, n_heads=num_heads)\n",
    "        self.feed_forward = PosWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None, is_causal=False):\n",
    "        #print(\"Q, K, V: \", x.size())\n",
    "        attn_output = self.self_attn(x, x, x, mask=mask, is_causal=is_causal) # self attention\n",
    "        x = self.norm1(x + self.dropout(attn_output)) # layer-norm + dropout + skip connection\n",
    "        ff_output = self.feed_forward(x) # feed-forward\n",
    "        x = self.norm2(x + self.dropout(ff_output)) # layer-norm + dropout + skip connection\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, num_heads, d_ff, dropout=0, N_layers=6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, d_hidden, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, d_hidden, num_heads)\n",
    "        self.feed_forward = PosWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask, is_causal=False):\n",
    "        attn_output = self.self_attn(x, x, x, mask=tgt_mask, is_causal=is_causal) # self attention\n",
    "        x = self.norm1(x + self.dropout(attn_output)) # layer-norm + dropout + skip connection\n",
    "        attn_output = self.cross_attn(q=x, k=enc_output, v=enc_output, mask=src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output)) # layer-norm + droput + skip connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output)) # layer-norm + dropout + skip connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, num_heads, d_ff,src_vocab_size, tgt_vocab_size, dropout=0, n_enc_layers=6, n_dec_layers=6):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.enc_layers = nn.Sequential(\n",
    "            *(EncoderLayer(d_model=d_model,\n",
    "                         d_hidden=d_hidden,\n",
    "                         num_heads=num_heads,\n",
    "                         d_ff=d_ff) for _ in range(n_enc_layers))\n",
    "        )\n",
    "        self.dec_layers = nn.Sequential(\n",
    "            *(DecoderLayer(d_model=d_model,\n",
    "                         d_hidden=d_hidden,\n",
    "                         d_ff=d_ff,\n",
    "                         num_heads=num_heads) for _ in range(n_enc_layers))\n",
    "        )\n",
    "\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model=d_model,\n",
    "                         d_hidden=d_hidden,\n",
    "                         num_heads=num_heads,\n",
    "                         d_ff=d_ff) for _ in range(n_enc_layers)]\n",
    "        )\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model=d_model,\n",
    "                         d_hidden=d_hidden,\n",
    "                         d_ff=d_ff,\n",
    "                         num_heads=num_heads) for _ in range(n_dec_layers)]\n",
    "        )\n",
    "\n",
    "        self.pos_encoding_layer = PositionEncoding2(d_embed=d_model)\n",
    "\n",
    "        self.src_embedding = nn.Embedding(embedding_dim=d_model, num_embeddings=src_vocab_size, padding_idx=PAD_IDX)\n",
    "        self.tgt_embedding = nn.Embedding(embedding_dim=d_model, num_embeddings=tgt_vocab_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.final = nn.Linear(in_features=d_hidden, out_features=tgt_vocab_size)\n",
    "\n",
    "    def forward(self, inp_seq, tgt_seq, inp_mask=None, tgt_mask=None, is_causal_tgt=False):\n",
    "        \n",
    "\n",
    "        inp_seq = self.src_embedding(inp_seq)\n",
    "        inp_seq = self.pos_encoding_layer(inp_seq)\n",
    "\n",
    "        for enc in self.enc_layers:\n",
    "            inp_seq = enc(inp_seq, mask=inp_mask, is_causal=False)\n",
    "\n",
    "        # inp_seq = self.enc_layers(inp_seq, mask=inp_mask, is_causal=False)\n",
    "\n",
    "        tgt_seq = self.src_embedding(tgt_seq)\n",
    "        # tgt_seq = self.dec_layers(x=tgt_seq, enc_out=inp_seq, mask=tgt_mask, is_causal=is_causal_tgt)\n",
    "        for dec in self.dec_layers:\n",
    "            tgt_seq = dec(x=tgt_seq, enc_output=inp_seq, src_mask=inp_mask, tgt_mask=tgt_mask, is_causal=is_causal_tgt)\n",
    "\n",
    "        out_logits = self.final(tgt_seq)\n",
    "        return out_logits\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([2, 4, 3, 2])\n",
      "k_shape:  torch.Size([2, 4, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]),\n",
       " tensor([[[ 0.1143,  0.5827,  0.8509,  0.0893,  0.5163,  0.0677,  0.2451],\n",
       "          [ 0.1016,  0.6294,  1.2496,  0.1888,  0.1746,  0.0451,  0.5261],\n",
       "          [-0.1391,  0.3125,  1.0679,  0.1216,  0.2211,  0.0486,  0.6876]],\n",
       " \n",
       "         [[ 0.1143,  0.5827,  0.8509,  0.0893,  0.5163,  0.0677,  0.2451],\n",
       "          [ 0.1016,  0.6294,  1.2496,  0.1888,  0.1746,  0.0451,  0.5261],\n",
       "          [-0.1391,  0.3125,  1.0679,  0.1216,  0.2211,  0.0486,  0.6876]]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Transformer(d_model=8, d_hidden=8, num_heads=4, d_ff=10, src_vocab_size=3, tgt_vocab_size=7)\n",
    "src, tgt = torch.arange(0, 3).tile(2, 1), torch.arange(0, 3).tile(2, 1)\n",
    "\n",
    "src.shape, t(src, tgt)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    print(batch)\n",
    "    src_batch, tgt_batch = list(zip(*batch))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX).T\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX).T\n",
    "\n",
    "    return src_batch, tgt_batch \n",
    "\n",
    "p = list(zip(*tokenized_test_iter))\n",
    "# list(tokenized_test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_tokenizer.decode((pad_sequence(p[0], padding_value=PAD_IDX).transpose(-1, -2))[1013].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_batch = list(test_iter)#train_iter#list(train_iter)\n",
    "# collated_samp = collate_fn(tokenized_test_iter)\n",
    "# uncolled = list(tokenized_test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,   249,   314,   399,   248, 15587,   251,   567,   142,     3,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated_samp[0][len(collated_samp[0])-3]\n",
    "# uncolled = list(tokenized_test_iter)\n",
    "# l_iter = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 1015)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncolled), len(collated_samp[0]) #(1015, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([   2,  214,  340,  262, 1094, 5908, 1656, 1455, 3317,  203,  227, 2816,\n",
       "             3]),\n",
       "  tensor([   2,  120,  297,  181,  225,  201, 2938, 4989, 1104,   83,  923,    3])),\n",
       " tensor([   2,  214,  340,  262, 1094, 5908, 1656, 1455, 3317,  203,  227, 2816,\n",
       "            3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1]),\n",
       " tensor(15587))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncolled[0], collated_samp[0][0], torch.max(collated_samp[0][len(collated_samp[0])-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in train_dataloader:\n",
    "#     print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "D_MODEL = 512\n",
    "D_FF = 2048\n",
    "N_HEADS = 8\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cpu'\n",
    "LR = math.sqrt(D_MODEL/4000) # make this a schedule\n",
    "BETAS = (0.9, 0.98)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(tokenized_test_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(tokenized_valid_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, data_loader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    # train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "    data_count = 0\n",
    "    import tqdm\n",
    "    for src, tgt in tqdm.tqdm(data_loader):#train_dataloader):\n",
    "        data_count+=1\n",
    "        if data_count==100:\n",
    "            break\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        out_logits = model(src, tgt, is_causal_tgt=True)\n",
    "\n",
    "        print(\"out_logits shape: \", out_logits.shape)\n",
    "        print(\"tgt shape: \", tgt.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(out_logits.transpose(-1, -2), tgt)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    print(\"Trained on %s datapts\"%data_count)\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    data_count=0\n",
    "    for src, tgt in val_dataloader:\n",
    "        data_count+=1\n",
    "        if data_count==50:\n",
    "            break\n",
    "        src = src.to(DEVICE).T\n",
    "        tgt = tgt.to(DEVICE).T\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        print(\"src\", src.T.shape)\n",
    "        print(\"tgt\", tgt.T.shape)\n",
    "\n",
    "        # src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        # logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        output = model(src, tgt[:,:-1])\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "        loss = criterion(output.contiguous().view(-1, TGT_VOCAB_SIZE), tgt[:, 1:].contiguous().view(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Transformer(d_model=D_MODEL, \n",
    "                    d_hidden=D_MODEL, \n",
    "                    num_heads=N_HEADS, \n",
    "                    d_ff=D_FF, \n",
    "                    src_vocab_size=de_tokenizer.get_vocab_size(), \n",
    "                    tgt_vocab_size=en_tokenizer.get_vocab_size()\n",
    "                    )\n",
    "\n",
    "optimizer = torch.optim.Adam(betas=BETAS, eps=10e-9, lr=LR, params=model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_tokenizer.get_vocab_size()\n",
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer, train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = 0#evaluate(model)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'model_stock/oct2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, mask = torch.ones((32, 8, 23, 64)), torch.ones((32, 8, 24, 64)), torch.ones((23, 24))\n",
    "attn_scores = torch.softmax(\n",
    "            einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(2) + mask,#torch.FloatTensor(self.d_hidden//8)),\n",
    "            dim=-1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 23, 24])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(2)).shape# + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (1, 1)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 1, 64])\n",
      "mask shape:  (1, 10)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (1, 1)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 1, 64])\n",
      "mask shape:  (1, 10)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (1, 1)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 1, 64])\n",
      "mask shape:  (1, 10)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (1, 1)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 1, 64])\n",
      "mask shape:  (1, 10)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (1, 1)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 1, 64])\n",
      "mask shape:  (1, 10)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (1, 1)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 1, 64])\n",
      "mask shape:  (1, 10)\n",
      "q_shape:  torch.Size([1, 8, 1, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (2, 2)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 2, 64])\n",
      "mask shape:  (2, 10)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (2, 2)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 2, 64])\n",
      "mask shape:  (2, 10)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (2, 2)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 2, 64])\n",
      "mask shape:  (2, 10)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (2, 2)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 2, 64])\n",
      "mask shape:  (2, 10)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (2, 2)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 2, 64])\n",
      "mask shape:  (2, 10)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (2, 2)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 2, 64])\n",
      "mask shape:  (2, 10)\n",
      "q_shape:  torch.Size([1, 8, 2, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 3, 64])\n",
      "mask shape:  (3, 10)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 3, 64])\n",
      "mask shape:  (3, 10)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 3, 64])\n",
      "mask shape:  (3, 10)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 3, 64])\n",
      "mask shape:  (3, 10)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 3, 64])\n",
      "mask shape:  (3, 10)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (3, 3)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 3, 64])\n",
      "mask shape:  (3, 10)\n",
      "q_shape:  torch.Size([1, 8, 3, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (4, 4)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 4, 64])\n",
      "mask shape:  (4, 10)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (4, 4)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 4, 64])\n",
      "mask shape:  (4, 10)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (4, 4)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 4, 64])\n",
      "mask shape:  (4, 10)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (4, 4)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 4, 64])\n",
      "mask shape:  (4, 10)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (4, 4)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 4, 64])\n",
      "mask shape:  (4, 10)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (4, 4)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 4, 64])\n",
      "mask shape:  (4, 10)\n",
      "q_shape:  torch.Size([1, 8, 4, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (5, 5)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 5, 64])\n",
      "mask shape:  (5, 10)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (5, 5)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 5, 64])\n",
      "mask shape:  (5, 10)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (5, 5)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 5, 64])\n",
      "mask shape:  (5, 10)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (5, 5)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 5, 64])\n",
      "mask shape:  (5, 10)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (5, 5)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 5, 64])\n",
      "mask shape:  (5, 10)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (5, 5)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 5, 64])\n",
      "mask shape:  (5, 10)\n",
      "q_shape:  torch.Size([1, 8, 5, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (6, 6)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 6, 64])\n",
      "mask shape:  (6, 10)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (6, 6)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 6, 64])\n",
      "mask shape:  (6, 10)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (6, 6)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 6, 64])\n",
      "mask shape:  (6, 10)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (6, 6)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 6, 64])\n",
      "mask shape:  (6, 10)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (6, 6)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 6, 64])\n",
      "mask shape:  (6, 10)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (6, 6)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 6, 64])\n",
      "mask shape:  (6, 10)\n",
      "q_shape:  torch.Size([1, 8, 6, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (7, 7)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 7, 64])\n",
      "mask shape:  (7, 10)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (7, 7)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 7, 64])\n",
      "mask shape:  (7, 10)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (7, 7)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 7, 64])\n",
      "mask shape:  (7, 10)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (7, 7)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 7, 64])\n",
      "mask shape:  (7, 10)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (7, 7)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 7, 64])\n",
      "mask shape:  (7, 10)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (7, 7)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 7, 64])\n",
      "mask shape:  (7, 10)\n",
      "q_shape:  torch.Size([1, 8, 7, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (8, 8)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 8, 64])\n",
      "mask shape:  (8, 10)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (8, 8)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 8, 64])\n",
      "mask shape:  (8, 10)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (8, 8)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 8, 64])\n",
      "mask shape:  (8, 10)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (8, 8)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 8, 64])\n",
      "mask shape:  (8, 10)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (8, 8)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 8, 64])\n",
      "mask shape:  (8, 10)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (8, 8)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 8, 64])\n",
      "mask shape:  (8, 10)\n",
      "q_shape:  torch.Size([1, 8, 8, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (9, 9)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 9, 64])\n",
      "mask shape:  (9, 10)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (9, 9)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 9, 64])\n",
      "mask shape:  (9, 10)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (9, 9)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 9, 64])\n",
      "mask shape:  (9, 10)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (9, 9)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 9, 64])\n",
      "mask shape:  (9, 10)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (9, 9)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 9, 64])\n",
      "mask shape:  (9, 10)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (9, 9)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 9, 64])\n",
      "mask shape:  (9, 10)\n",
      "q_shape:  torch.Size([1, 8, 9, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n",
      "mask shape:  (10, 10)\n",
      "q_shape:  torch.Size([1, 8, 10, 64])\n",
      "k_shape:  torch.Size([1, 8, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "y_toks = [BOS_IDX]\n",
    "src_toks = de_tokenizer.encode(de_data[4]).ids\n",
    "model.eval()\n",
    "toks_generated=0\n",
    "max_len=10#100\n",
    "while y_toks[-1] != EOS_IDX and toks_generated < max_len:\n",
    "    toks_generated+=1\n",
    "    out_logits = model(torch.tensor(src_toks).unsqueeze(0), torch.tensor(y_toks).unsqueeze(0), is_causal_tgt=True)\n",
    "    # print(out_logits[:,-1].shape, \"sfdsfhadsfhsdkjhfSDFfdf\")\n",
    "    idx_predicted = torch.argmax(out_logits[:,-1])\n",
    "    y_toks.append(idx_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2,\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456),\n",
       "  tensor(2456)],\n",
       " 'lots lots lots lots lots lots lots lots lots lots',\n",
       " 'Two men are at the stove preparing food.')"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_toks,\n",
    "en_tokenizer.decode(y_toks),#[2456]),\n",
    "en_data[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
