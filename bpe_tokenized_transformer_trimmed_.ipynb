{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import einops\n",
    "from tokenizers import CharBPETokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import huggingface char-bpe tokenizer\n",
    "en_tokenizer, de_tokenizer = CharBPETokenizer(), CharBPETokenizer()\n",
    "\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "en_tokenizer.add_special_tokens(special_symbols)\n",
    "de_tokenizer.add_special_tokens(special_symbols)\n",
    "\n",
    "# Train tokenizers\n",
    "train_iter, test_iter, valid_iter = Multi30k(language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "\n",
    "de_data, en_data = (list(zip(*train_iter)))\n",
    "en_tokenizer.train_from_iterator(iterator=en_data)\n",
    "de_tokenizer.train_from_iterator(iterator=de_data)\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = tuple(en_tokenizer.encode(x).ids[0] for x in special_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=11, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer.encode(en_data[0])#.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform_en = lambda x : torch.tensor([BOS_IDX] + en_tokenizer.encode(x.rstrip(\"\\n\")).ids + [EOS_IDX])\n",
    "text_transform_de = lambda x : torch.tensor([BOS_IDX] + de_tokenizer.encode(x.rstrip(\"\\n\")).ids + [EOS_IDX])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(list(train_iter), dtype=torch.StringType)\n",
    "# type(train_iter)\n",
    "# (list(zip(*train_iter)))[0][9]\n",
    "# en_data, de_data = (list(zip(*train_iter)))\n",
    "# de_data_tokenized, en_data_tokenized = \n",
    "# map(lambda x : (x[0], x[1]), train_iter)#list(map(text_transform_de, de_data)), list(map(text_transform_de, de_data))\n",
    "# # de_data_tokenized\n",
    "# tokenized_multik3 = list(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenized_multik3), len(list(train_iter)), type(train_iter)\n",
    "# torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(tokenized_multik3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter)))\n",
    "tokenized_train_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter))\n",
    "tokenized_test_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), test_iter))\n",
    "tokenized_valid_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), valid_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(tokenized_train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Position encoding\"\"\"\n",
    "class PositionEncoding2(nn.Module):\n",
    "    def __init__(self, d_embed):\n",
    "        super(PositionEncoding2, self).__init__()\n",
    "        self.d_embed = d_embed\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def get_position_encoding(self, seq_len):\n",
    "        encoding = torch.zeros((seq_len, self.d_embed))\n",
    "        dimensions = torch.arange(0, self.d_embed//2)\n",
    "        timesteps = torch.arange(0, seq_len)\n",
    "\n",
    "        encoding[:, 0::2] = torch.sin(torch.einsum('i,j -> ji', 1/(10000**(2*dimensions/self.d_embed)), timesteps))\n",
    "        encoding[:, 1::2] = torch.cos(torch.einsum('i,j -> ji', 1/(10000**(2*dimensions/self.d_embed)), timesteps))\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        pos_encoding = nn.Parameter(self.get_position_encoding(seq_len=inp.shape[-2]), requires_grad=False)\n",
    "        return self.dropout(inp + pos_encoding) # + dropout ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Multihead attention\"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, n_heads):\n",
    "        super().__init__()#MultiheadAttention)\n",
    "        self.d_hidden=d_hidden\n",
    "        self.n_heads = n_heads\n",
    "        self.W_q = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden//n_heads)))\n",
    "        )\n",
    "        self.W_k = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden//n_heads)))\n",
    "        )\n",
    "        self.W_v = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden//n_heads)))\n",
    "        )\n",
    "\n",
    "        self.W_o = nn.Linear(in_features=d_hidden, out_features=d_model, bias=False)\n",
    "\n",
    "    def forward(self, q, k, v, get_attn_scores=False, mask=None, is_causal=False):\n",
    "        mask_shape = (q.shape[-2], k.shape[-2]) \n",
    "        # print(\"mask shape: \", mask_shape)\n",
    "        mask = mask if mask else (self.causal_mask(self.n_heads, mask_shape) if is_causal else self.empty_mask(self.n_heads, mask_shape))\n",
    "\n",
    "        # Compute Q, K, V (matrix multiplication, batched along heads)\n",
    "        q = einops.einsum(self.W_q, q, 'h d_model d_h, b T d_model -> b h  T d_h') # T is timesteps (sequence length)\n",
    "        k = einops.einsum(self.W_k, k, 'h d_model d_h, b T d_model -> b h  T d_h')\n",
    "        v = einops.einsum(self.W_v, v, 'h d_model d_h, b T d_model -> b h  T d_h')\n",
    "\n",
    "        # print(\"q_shape: \", q.shape)\n",
    "        # print(\"k_shape: \", k.shape)\n",
    "\n",
    "        attn_scores = torch.softmax(\n",
    "            einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(self.d_hidden//self.n_heads) + mask,#torch.FloatTensor(self.d_hidden//8)),\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "        attn_head_outs = einops.einsum(attn_scores, v, '... T_out T_in, ... T_in d_h -> ... T_out d_h')\n",
    "        # print(attn_head_outs.shape)\n",
    "        # print(attn_scores, \"mask: \", mask)\n",
    "        # print(\"mask: \", mask)\n",
    "        concatted_outs = einops.rearrange(attn_head_outs, 'b h T_out d_h -> b T_out (h d_h)')\n",
    "        concatted_outs = self.W_o(concatted_outs)\n",
    "\n",
    "        return (concatted_outs, attn_scores) if get_attn_scores else concatted_outs\n",
    "    \n",
    "    @classmethod\n",
    "    def causal_mask(cls, n_heads, mask_shape):\n",
    "        return einops.repeat(\n",
    "            torch.triu(\n",
    "                torch.fill(torch.zeros(mask_shape),  -torch.inf),\n",
    "                diagonal=1\n",
    "                )\n",
    "            , pattern='... -> k ...', k=n_heads\n",
    "            )\n",
    "    \n",
    "    @classmethod\n",
    "    def empty_mask(cls, n_heads, mask_shape):\n",
    "        return einops.repeat(\n",
    "            torch.zeros(mask_shape) , pattern='... -> k ...', k=n_heads\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Multihead attention\"\"\"\n",
    "class MultiHeadAttention2(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, n_heads):\n",
    "        super().__init__()#MultiheadAttention)\n",
    "        self.d_hidden=d_hidden\n",
    "        self.n_heads = n_heads\n",
    "        # self.W_q = nn.Parameter(\n",
    "        #     nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden)))\n",
    "        # )\n",
    "        # self.W_k = nn.Parameter(\n",
    "        #     nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden)))\n",
    "        # )\n",
    "        # self.W_v = nn.Parameter(\n",
    "        #     nn.init.xavier_normal_(torch.zeros((n_heads, d_model, d_hidden)))\n",
    "        # )\n",
    "\n",
    "        self.W_q = nn.Linear(in_features=d_model, out_features=d_hidden)\n",
    "        self.W_k = nn.Linear(in_features=d_model, out_features=d_hidden)\n",
    "        self.W_v = nn.Linear(in_features=d_model, out_features=d_hidden)\n",
    "\n",
    "        self.W_o = nn.Linear(in_features=d_hidden, out_features=d_model, bias=False)\n",
    "\n",
    "    def forward(self, q, k, v, get_attn_scores=False, mask=None, is_causal=False):\n",
    "        mask_shape = (q.shape[-2], k.shape[-2]) \n",
    "        # print(\"mask shape: \", mask_shape)\n",
    "        mask = mask if mask else (self.causal_mask(self.n_heads, mask_shape) if is_causal else self.empty_mask(self.n_heads, mask_shape))\n",
    "        # print(\"in q\", k.shape)\n",
    "        # Compute Q, K, V (matrix multiplication, batched along heads)\n",
    "        q = self.W_q(q)#einops.einsum(self.W_q, q, 'h d_model d_h, b T d_model -> b h T d_h') # T is timesteps (sequence length)\n",
    "        k = self.W_k(k)#einops.einsum(self.W_k, k, 'h d_model d_h, b T d_model -> b h T d_h')\n",
    "        v = self.W_v(v)#einops.einsum(self.W_v, v, 'h d_model d_h, b T d_model -> b h T d_h')\n",
    "        # print(\"out1 q\", k.shape)\n",
    "        # q = einops.rearrange(q, 'b T d_h -> b T h k', h=self.n_heads)\n",
    "        q = einops.rearrange(q, 'b T (h w) -> b h T w', h=self.n_heads)\n",
    "        k = einops.rearrange(k, 'b T (h w) -> b h T w', h=self.n_heads)\n",
    "        v = einops.rearrange(v, 'b T (h w) -> b h T w', h=self.n_heads)\n",
    "        # print(\"q_shape: \", q.shape)\n",
    "        # print(\"k_shape: \", k.shape)\n",
    "        # print(\"out2 q\", k.shape)\n",
    "\n",
    "        attn_scores = torch.softmax(\n",
    "            einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(self.d_hidden//self.n_heads) + mask,#torch.FloatTensor(self.d_hidden//8)),\n",
    "            dim=-1\n",
    "        )\n",
    "\n",
    "        attn_head_outs = einops.einsum(attn_scores, v, '... T_out T_in, ... T_in d_h -> ... T_out d_h')\n",
    "        # print(attn_head_outs.shape)\n",
    "        # print(attn_scores, \"mask: \", mask)\n",
    "        # print(\"mask: \", mask)\n",
    "        concatted_outs = einops.rearrange(attn_head_outs, 'b h T_out d_h -> b T_out (h d_h)')\n",
    "        concatted_outs = self.W_o(concatted_outs)\n",
    "\n",
    "        return (concatted_outs, attn_scores) if get_attn_scores else concatted_outs\n",
    "    \n",
    "    @classmethod\n",
    "    def causal_mask(cls, n_heads, mask_shape):\n",
    "        return einops.repeat(\n",
    "            torch.triu(\n",
    "                torch.fill(torch.zeros(mask_shape),  -torch.inf),\n",
    "                diagonal=1\n",
    "                )\n",
    "            , pattern='... -> k ...', k=n_heads\n",
    "            )\n",
    "    \n",
    "    @classmethod\n",
    "    def empty_mask(cls, n_heads, mask_shape):\n",
    "        return einops.repeat(\n",
    "            torch.zeros(mask_shape) , pattern='... -> k ...', k=n_heads\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],\n",
       "\n",
       "         [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],\n",
       "\n",
       "         [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]]],\n",
       "\n",
       "\n",
       "        [[[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],\n",
       "\n",
       "         [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],\n",
       "\n",
       "         [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667],\n",
       "          [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, h, T_out, d_h = 2, 3, 4, 6\n",
    "q = torch.ones((b, h, T_out, d_h)) # target seq\n",
    "k = torch.ones((b, h, T_out+2, d_h)) # inp seq\n",
    "\n",
    "mask = MultiHeadAttention2.empty_mask(n_heads=h, mask_shape=(q.shape[-2], k.shape[-2]))#(k.shape[-2], q.shape[-2]))\n",
    "# mask = \n",
    "# print(mask)\n",
    "attn_scores = torch.softmax(\n",
    "            einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(2) + mask,#torch.FloatTensor(self.d_hidden//8)),\n",
    "            dim=-1\n",
    "        )\n",
    "attn_scores#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0915, -0.5712,  1.2721, -0.3021,  0.7753,  0.3741],\n",
      "         [-0.1946, -0.4819,  0.8439,  0.3889, -0.3510, -0.6231],\n",
      "         [-0.8813, -0.0814,  1.3627,  0.1860,  0.1811, -0.1485],\n",
      "         [-0.7180, -0.7588,  1.0270, -0.4516,  0.7069,  0.0185]],\n",
      "\n",
      "        [[-0.6276, -0.3813,  0.9738, -0.0662,  0.3060,  0.1939],\n",
      "         [-0.8500, -0.8558,  0.8711, -0.5391,  0.8880,  0.7814],\n",
      "         [-1.5107,  0.5947,  1.3644,  0.5068, -0.0897, -0.0935],\n",
      "         [-0.2300,  0.1176,  0.9877,  0.3936,  0.5128,  0.4988]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-1.0915, -0.5712],\n",
      "          [-0.1946, -0.4819],\n",
      "          [-0.8813, -0.0814],\n",
      "          [-0.7180, -0.7588]],\n",
      "\n",
      "         [[ 1.2721, -0.3021],\n",
      "          [ 0.8439,  0.3889],\n",
      "          [ 1.3627,  0.1860],\n",
      "          [ 1.0270, -0.4516]],\n",
      "\n",
      "         [[ 0.7753,  0.3741],\n",
      "          [-0.3510, -0.6231],\n",
      "          [ 0.1811, -0.1485],\n",
      "          [ 0.7069,  0.0185]]],\n",
      "\n",
      "\n",
      "        [[[-0.6276, -0.3813],\n",
      "          [-0.8500, -0.8558],\n",
      "          [-1.5107,  0.5947],\n",
      "          [-0.2300,  0.1176]],\n",
      "\n",
      "         [[ 0.9738, -0.0662],\n",
      "          [ 0.8711, -0.5391],\n",
      "          [ 1.3644,  0.5068],\n",
      "          [ 0.9877,  0.3936]],\n",
      "\n",
      "         [[ 0.3060,  0.1939],\n",
      "          [ 0.8880,  0.7814],\n",
      "          [-0.0897, -0.0935],\n",
      "          [ 0.5128,  0.4988]]]], grad_fn=<PermuteBackward0>)\n"
     ]
    }
   ],
   "source": [
    "q.shape\n",
    "q = torch.ones((b, T_out, d_h))\n",
    "s = MultiHeadAttention2(d_model=d_h, d_hidden=d_h, n_heads=h)\n",
    "ti = PositionEncoding2(d_embed=d_h)\n",
    "q = ti(q)\n",
    "q = s.W_q(q)\n",
    "q.shape\n",
    "print(q)\n",
    "q = einops.rearrange(q, 'b T (h w) -> b h T w', h=h)#, w=d_h//h)\n",
    "q.shape, q\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model=512, d_ff=2048):\n",
    "        super(PosWiseFeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # FFN(x) = max(0, xW1 + b1)W2 + b2 ; f(x) = max(0, x) is relu\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder and Decoder\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, num_heads, d_ff, dropout=0.1, N_layers=6):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model=d_model, d_hidden=d_hidden, n_heads=num_heads)\n",
    "        self.feed_forward = PosWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None, is_causal=False):\n",
    "        #print(\"Q, K, V: \", x.size())\n",
    "        attn_output = self.self_attn(x, x, x, mask=mask, is_causal=is_causal) # self attention\n",
    "        x = self.norm1(x + self.dropout(attn_output)) # layer-norm + dropout + skip connection\n",
    "        ff_output = self.feed_forward(x) # feed-forward\n",
    "        x = self.norm2(x + self.dropout(ff_output)) # layer-norm + dropout + skip connection\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, num_heads, d_ff, dropout=0.1, N_layers=6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, d_hidden, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, d_hidden, num_heads)\n",
    "        self.feed_forward = PosWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask, is_causal=False):\n",
    "        attn_output = self.self_attn(x, x, x, mask=tgt_mask, is_causal=is_causal) # self attention\n",
    "        x = self.norm1(x + self.dropout(attn_output)) # layer-norm + dropout + skip connection\n",
    "        attn_output = self.cross_attn(q=x, k=enc_output, v=enc_output, mask=src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output)) # layer-norm + droput + skip connection\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output)) # layer-norm + dropout + skip connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, d_hidden, num_heads, d_ff,src_vocab_size, tgt_vocab_size, dropout=0, n_enc_layers=6, n_dec_layers=6):\n",
    "        super(Transformer, self).__init__()\n",
    "        # self.enc_layers = nn.Sequential(\n",
    "        #     *(EncoderLayer(d_model=d_model,\n",
    "        #                  d_hidden=d_hidden,\n",
    "        #                  num_heads=num_heads,\n",
    "        #                  d_ff=d_ff) for _ in range(n_enc_layers))\n",
    "        # )\n",
    "        # self.dec_layers = nn.Sequential(\n",
    "        #     *(DecoderLayer(d_model=d_model,\n",
    "        #                  d_hidden=d_hidden,\n",
    "        #                  d_ff=d_ff,\n",
    "        #                  num_heads=num_heads) for _ in range(n_enc_layers))\n",
    "        # )\n",
    "\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model=d_model,\n",
    "                         d_hidden=d_hidden,\n",
    "                         num_heads=num_heads,\n",
    "                         d_ff=d_ff) for _ in range(n_enc_layers)]\n",
    "        )\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model=d_model,\n",
    "                         d_hidden=d_hidden,\n",
    "                         d_ff=d_ff,\n",
    "                         num_heads=num_heads) for _ in range(n_dec_layers)]\n",
    "        )\n",
    "\n",
    "        self.pos_encoding_layer = PositionEncoding2(d_embed=d_model)\n",
    "\n",
    "        self.src_embedding = nn.Embedding(embedding_dim=d_model, num_embeddings=src_vocab_size, padding_idx=PAD_IDX)\n",
    "        self.tgt_embedding = nn.Embedding(embedding_dim=d_model, num_embeddings=tgt_vocab_size, padding_idx=PAD_IDX)\n",
    "\n",
    "        self.final = nn.Linear(in_features=d_hidden, out_features=tgt_vocab_size)\n",
    "\n",
    "    def forward(self, inp_seq, tgt_seq, inp_mask=None, tgt_mask=None, is_causal_tgt=False):\n",
    "        \n",
    "\n",
    "        inp_seq = self.src_embedding(inp_seq)\n",
    "        inp_seq = self.pos_encoding_layer(inp_seq)\n",
    "\n",
    "        for enc in self.enc_layers:\n",
    "            inp_seq = enc(inp_seq, mask=inp_mask, is_causal=False)\n",
    "\n",
    "        # inp_seq = self.enc_layers(inp_seq, mask=inp_mask, is_causal=False)\n",
    "\n",
    "        tgt_seq = self.src_embedding(tgt_seq)\n",
    "        # tgt_seq = self.dec_layers(x=tgt_seq, enc_out=inp_seq, mask=tgt_mask, is_causal=is_causal_tgt)\n",
    "        for dec in self.dec_layers:\n",
    "            tgt_seq = dec(x=tgt_seq, enc_output=inp_seq, src_mask=inp_mask, tgt_mask=tgt_mask, is_causal=is_causal_tgt)\n",
    "\n",
    "        out_logits = self.final(tgt_seq)\n",
    "        return out_logits\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]),\n",
       " tensor([[[-0.5123,  0.6123,  0.4138, -0.6868, -0.0120, -0.6168,  0.0660],\n",
       "          [-0.2988,  0.8658,  0.3645, -0.4842, -0.2050, -0.7479, -0.1059],\n",
       "          [-0.4016,  0.6682,  0.4790, -0.5985,  0.2125, -0.4946, -0.1214]],\n",
       " \n",
       "         [[-0.7274,  0.3957,  0.1740, -0.6914,  0.0929, -0.6376,  0.4161],\n",
       "          [-0.7089,  0.5095,  0.2555, -0.6303,  0.3580, -0.3460,  0.2380],\n",
       "          [-0.7822,  0.0296,  0.3872, -0.7767,  0.3205, -0.1270,  0.5384]]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Transformer(d_model=8, d_hidden=8, num_heads=4, d_ff=10, src_vocab_size=3, tgt_vocab_size=7)\n",
    "src, tgt = torch.arange(0, 3).tile(2, 1), torch.arange(0, 3).tile(2, 1)\n",
    "\n",
    "src.shape, t(src, tgt)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # print(batch)\n",
    "    src_batch, tgt_batch = list(zip(*batch))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX).transpose(-1, -2)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX).transpose(-1, -2)\n",
    "\n",
    "    return src_batch, tgt_batch \n",
    "\n",
    "p = list(zip(*tokenized_test_iter))\n",
    "# list(tokenized_test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_tokenizer.decode((pad_sequence(p[0], padding_value=PAD_IDX).transpose(-1, -2))[1013].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_batch = list(test_iter)#train_iter#list(train_iter)\n",
    "# collated_samp = collate_fn(tokenized_test_iter)\n",
    "# uncolled = list(tokenized_test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collated_samp[0][len(collated_samp[0])-3]\n",
    "# uncolled = list(tokenized_test_iter)\n",
    "# l_iter = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(uncolled), len(collated_samp[0]) #(1015, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncolled[0], collated_samp[0][0], torch.max(collated_samp[0][len(collated_samp[0])-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   2,  313,  400,  826, 1276,    3]),\n",
       " tensor([   2, 1859, 2613, 5024, 3934,    3]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for t in train_dataloader:\n",
    "#     print(t)\n",
    "text_transform_en('one two three four'), text_transform_en('five six seven eight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "D_MODEL = 512\n",
    "D_FF = 2048\n",
    "N_HEADS = 8\n",
    "\n",
    "BATCH_SIZE = 1#64\n",
    "DEVICE = 'cpu'\n",
    "LR = 0.00001#math.sqrt(D_MODEL/4000) # make this a schedule\n",
    "BETAS = (0.9, 0.98)\n",
    "\n",
    "# train_dataloader = DataLoader(tokenized_train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "# test_dataloader = DataLoader(tokenized_test_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "# valid_dataloader = DataLoader(tokenized_valid_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, data_loader=None):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    # train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # tokenized_train_iter = ('one two three four', 'five six seven eight')#torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter))\n",
    "    # tokenized_train_iter = [(torch.Tensor([   2,  313,  400,  826, 1276,    3]).long(), torch.Tensor([   2, 1357, 1694,  210,  139, 1016, 5501, 8206, 1386,    3]).long())]\n",
    "    # tokenized_train_iter = [(torch.Tensor([      2,  313,  400,  826, 1276,    3]).long(), torch.Tensor([   2, 1859, 2613, 5024, 3934,    3]).long())]\n",
    "    tokenized_train_iter = torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(map(lambda x : (text_transform_de(x[0]), text_transform_en(x[1])), train_iter))\n",
    "\n",
    "    train_dataloader = DataLoader(tokenized_train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)#[PAD_IDX, BOS_IDX])\n",
    "\n",
    "    data_count = 0\n",
    "    import tqdm\n",
    "    for src, tgt in tqdm.tqdm(train_dataloader):#data_loader):#train_dataloader):\n",
    "        data_count+=1\n",
    "        if data_count==100:\n",
    "            break\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        out_logits = model(src, tgt[:, :-1], is_causal_tgt=True)\n",
    "\n",
    "        # print(\"inputs: \", de_tokenizer.decode(src.squeeze().tolist()), en_tokenizer.decode(tgt[:, :-1]).squeeze().tolist())\n",
    "        print(\"inputs: \", de_tokenizer.decode(list(src.squeeze()), skip_special_tokens=False), en_tokenizer.decode(list(tgt[:, :-1].squeeze()), skip_special_tokens=False))\n",
    "\n",
    "\n",
    "        # print(\"out_logits shape: \", out_logits.shape)\n",
    "        # print(\"tgt shape: \", tgt.shape) b seq vcb\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print(\"out_logits: \", out_logits.transpose(-1, -2), out_logits.transpose(-1, -2).shape)\n",
    "        # print(\"tgt: \", tgt )\n",
    "        \n",
    "\n",
    "        loss = loss_fn(out_logits.transpose(-1, -2), tgt[:, 1:])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    print(\"Trained on %s datapts\"%data_count)\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    data_count=0\n",
    "    for src, tgt in val_dataloader:\n",
    "        data_count+=1\n",
    "        if data_count==50:\n",
    "            break\n",
    "        src = src.to(DEVICE).T\n",
    "        tgt = tgt.to(DEVICE).T\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        print(\"src\", src.T.shape)\n",
    "        print(\"tgt\", tgt.T.shape)\n",
    "\n",
    "        # src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        # logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        output = model(src, tgt[:,:-1])\n",
    "\n",
    "        \n",
    "\n",
    "        loss = loss_fn(output.transpose(-1, -2), tgt)\n",
    "        # loss = criterion(output.contiguous().view(-1, TGT_VOCAB_SIZE), tgt[:, 1:].contiguous().view(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Transformer(d_model=D_MODEL, \n",
    "                    d_hidden=D_MODEL, \n",
    "                    num_heads=N_HEADS, \n",
    "                    d_ff=D_FF, \n",
    "                    src_vocab_size=de_tokenizer.get_vocab_size(), \n",
    "                    tgt_vocab_size=en_tokenizer.get_vocab_size()\n",
    "                    )\n",
    "\n",
    "optimizer = torch.optim.Adam(betas=BETAS, eps=10e-9, lr=LR, params=model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche . <eos> <bos>Two young , White males are outside near many bushes .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem . <eos> <bos>Several men in hard hats are operating a giant pulley system .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein kleines Mädchen klettert in ein Spielhaus aus Holz . <eos> <bos>A little girl climbing into a wooden playhouse .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster . <eos> <bos>A man in a blue shirt is standing on a ladder cleaning a window .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei Männer stehen am Herd und bereiten Essen zu . <eos> <bos>Two men are at the stove preparing food .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann in grün hält eine Gitarre , während der andere Mann sein Hemd ansieht . <eos> <bos>A man in green holds a guitar while the other man observes his shirt .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:02,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann lächelt einen ausgestopften Löwen an . <eos> <bos>A man is smiling at a stuffed lion\n",
      "inputs:  <bos>Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt . <eos> <bos>A trendy girl talking on her cellphone while gliding slowly down the street .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:03,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine Frau mit einer großen Geldbörse geht an einem Tor vorbei . <eos> <bos>A woman with a large purse is walking by a gate .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:03,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Jungen tanzen mitten in der Nacht auf Pfosten . <eos> <bos>Boys dancing on poles in the middle of the night .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:03,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine Ballettklasse mit fünf Mädchen , die nacheinander springen . <eos> <bos>A ballet class of five girls jumping in sequence .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Vier Typen , von denen drei Hüte tragen und einer nicht , springen oben in einem Treppenhaus . <eos> <bos>Four guys three wearing hats one not are jumping at the top of a staircase .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:04,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein schwarzer Hund und ein gefleckter Hund kämpfen . <eos> <bos>A black dog and a spotted dog are fighting\n",
      "inputs:  <bos>Ein Mann in einer neongrünen und orangefarbenen Uniform fährt auf einem grünen Traktor . <eos> <bos>A man in a neon green and orange uniform is driving on a green tractor .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:04,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Mehrere Frauen warten in einer Stadt im Freien . <eos> <bos>Several women wait outside in a city .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:05,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine Frau mit schwarzem Oberteil und Brille streut Puderzucker auf einem Gugelhupf . <eos> <bos>A lady in a black top with glasses is sprinkling powdered sugar on a bundt cake .\n",
      "inputs:  <bos>Ein kleines Mädchen sitzt vor einem großen gemalten Regenbogen . <eos> <bos>A little girl is sitting in front of a large painted rainbow .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:05,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann liegt auf der Bank , an die auch ein weißer Hund angebunden ist . <eos> <bos>A man lays on the bench to which a white dog is also tied .\n",
      "inputs:  <bos>Fünf Personen sitzen mit Instrumenten im Kreis . <eos> <bos>Five people are sitting in a circle with instruments .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:05,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine Gruppe älterer Frauen spielt zusammen Klarinette von Notenblättern . <eos> <bos>A bunch of elderly women play their clarinets together as they read off sheet music .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein großes Bauwerk ist kaputt gegangen und liegt auf einer Fahrbahn . <eos> <bos>A large structure has broken and is laying in a roadway .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:06,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine große Menschenmenge steht außen vor dem Eingang einer Metrostation . <eos> <bos>A large crowd of people stand outside in front of the entrance to a Metro station .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:07,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann , der ein Tattoo auf seinem Rücken erhält . <eos> <bos>A man getting a tattoo on his back .\n",
      "inputs:  <bos>Zwei Kinder sitzen auf einer kleinen Wippe im Sand . <eos> <bos>Two children sit on a small seesaw in the sand .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:07,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann , der eine reflektierende Weste und einen Schutzhelm trägt , hält eine Flagge in die Straße . <eos> <bos>A man wearing a reflective vest and a hard hat holds a flag in the road\n",
      "inputs:  <bos>Eine Person in einem blauen Mantel steht auf einem belebten Gehweg und betrachtet ein Gemälde einer Straßenszene . <eos> <bos>A person dressed in a blue coat is standing in on a busy sidewalk , studying painting of a street scene .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:07,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann in grünen Hosen läuft die Straße entlang . <eos> <bos>A man in green pants walking down the road .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:08,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Das kleine Kind klettert an roten Seilen auf einem Spielplatz . <eos> <bos>The small child climbs on a red ropes on a playground .\n",
      "inputs:  <bos>Du weißt , dass ich aussehe wie Justin Bieber . <eos> <bos>You know i am looking like Justin Bieber .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:08,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein junger Mann in einer schwarz - gelben Jacke blickt etwas an und lächelt . <eos> <bos>A young man in a black and yellow jacket is gazing at something and smiling .\n",
      "inputs:  <bos>Ein Mann , der mit einer Tasse Kaffee an einem Urinal steht . <eos> <bos>A man standing at a urinal with a coffee cup .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:08,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Fünf gehende Personen mit einem mehrfarbigen Himmel im Hintergrund . <eos> <bos>Five people walking with a multicolored sky in the background .\n",
      "inputs:  <bos>Ein alter Mann , der allein ein Bier trinkt . <eos> <bos>A old man having a beer alone .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:09,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein geschulter Polizeihund sitzt neben dem Hundeführer vor dem Polizeitransporter . <eos> <bos>A trained police dog sits next to his handler in front of the police van .\n",
      "inputs:  <bos>Eine Person fährt auf einer verschneiten Straße Fahrrad . <eos> <bos>A person riding a bike on a snowy road .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:09,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Fünf Männer , die alle weiße Hemden , Krawatten und schwarze Freizeithosen tragen , unterhalten sich hinter einem Lieferwagen . <eos> <bos>Five men , uniformly dressed in white shirts , tie and black slacks converse at the back of an open van .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:09,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann mit einem nach hinten gerichteten Hut arbeitet an Maschinen . <eos> <bos>A man with a backwards hat works on machinery .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:10,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine schwarze Frau und ein weißer Mann arbeiten in einer Fabrikumgebung und packen Gläser mit Kerzen in Kartons . <eos> <bos>A black woman and a white man working in a factory setting packing jars with candles into boxes .\n",
      "inputs:  <bos>Ein asiatischer Mann kehrt den Gehweg . <eos> <bos>Asian man sweeping the walkway .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:10,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann lehnt sich in ein Auto , um mit dem Fahrer zu reden , während ein Mann auf einem Fahrrad zusieht . <eos> <bos>A man leans into a car to talk to the driver , as a man on a bicycle looks on .\n",
      "inputs:  <bos>Zwei Kleinkinder im Freien auf dem Gras . <eos> <bos>Two young toddlers outside on the grass .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:10,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Leute sehen einer Person in einem seltsamen Fahrzeug auf einem Platz zu . <eos> <bos>People are watching a person in a weird vehicle in a plaza .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:11,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann geht an einem silbernen Fahrzeug vorbei . <eos> <bos>A man walks by a silver vehicle .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:11,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine schöne Braut geht auf einem Gehweg mit ihrem neuen Ehemann . <eos> <bos>A beautiful bride walking on a sidewalk with her new husband .\n",
      "inputs:  <bos>Ein kleiner Junge spielt bei McDonald ' s GameCube . <eos> <bos>A little boy playing GameCube at a McDonald ' s .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:11,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein weißer Hund schüttelt sich am Rande eines Strands mit einem orangefarbenen Ball . <eos> <bos>A white dog shakes on the edge of a beach with an orange ball .\n",
      "inputs:  <bos>Eine Gruppe von Personen , die im Park grillen . <eos> <bos>A group of people having a barbecue at a park .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:12,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann mit Sonnenbrille legt seinen Arm um eine Frau in einer schwarz - weißen Bluse . <eos> <bos>A man in sunglasses puts his arm around a woman in a black and white blouse .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:12,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann mit einem Luftballonhut und Leute , die im Freien an Picknicktischen essen . <eos> <bos>A man with a balloon hat and people eating outdoors at picnic tables .\n",
      "inputs:  <bos>Ein Junge , der während eines Taekwondo - Wettbewerbs einen Sprungtritt über drei Kinder macht und dabei auf Holz tritt . <eos> <bos>A boy jump kicking over three kids kicking wood during a tae kwon do competition .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:12,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Junge in einer roten Jacke , der Wasser auf einen Mann in einem weißen Hemd gießt . <eos> <bos>A boy in a red jacket pouring water on a man in a white shirt\n",
      "inputs:  <bos>Ein Mann mit einer roten Jacke , der sich vor der Sonne schützt und versucht , ein Stück Papier zu lesen . <eos> <bos>A man with a red jacket is shielding himself from the sun trying to read a piece of paper .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:13,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Männer , die eine Straße mit Kindern entlang laufen . <eos> <bos>Men walking down a street with children .\n",
      "inputs:  <bos>Ein kleiner Junge , der auf der Straße steht , während ein Mann in einem Overall an einer Steinwand arbeitet . <eos> <bos>A little boy is standing on the street while a man in overalls is working on a stone wall .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [00:13,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein schwarzer Hund springt über einen Baumstamm . <eos> <bos>A black dog leaps over a log .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:13,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann in einem Anzug rennt an zwei anderen Herren vorbei , die auch einen Anzug tragen . <eos> <bos>A man in a suit is running past two other gentleman , also dressed in a suit .\n",
      "inputs:  <bos>Ein Mann in einem roten Hemd , der mit dem Fahrrad um Wasser herum fährt . <eos> <bos>Man in a red shirt riding his bicycle around water .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:14,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann , der barfuß ist , olivgrüne kurze Hosen trägt , auf einem kleinen Propangasgrill Hotdogs grillt und gleichzeitig eine blaue Kunststofftasse hält . <eos> <bos>A barefooted man wearing olive green shorts grilling hotdogs on a small propane grill while holding a blue plastic cup .\n",
      "inputs:  <bos>Ein Hund rennt im Schnee . <eos> <bos>A dog is running in the snow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:14,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Eine Menschenmenge steht und wartet , bis die Ampel grün wird . <eos> <bos>A crowd is standing and waiting for the green light .\n",
      "inputs:  <bos>Mann auf Skiern , das zu verkaufende Kunstwerke im Schnee betrachtet . <eos> <bos>Man on skis looking at artwork for sale in the snow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:14,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Sieben Kletterer klettern eine Felswand hoch , während ein anderer Mann dasteht und das Seil hält . <eos> <bos>Seven climbers are ascending a rock face whilst another man stands holding the rope .\n",
      "inputs:  <bos>Der gelenkige Körper des jungen Turners schwebt über dem Schwebebalken . <eos> <bos>The young gymnast ' s supple body soars above the balance beam .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:15,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Junge schiebt ein Spielzeug - Geländefahrzeug um einen Gummi - Pool . <eos> <bos>A young boy is pushing a toy ATV around a rubber pool\n",
      "inputs:  <bos>Eine Frau in einer roten Windjacke , die über ein auf einem Dach installiertes Fernrohr auf die darunterliegende Stadt blickt . <eos> <bos>Woman in red windbreaker looking though a rooftop binoculars at the city below .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:15,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann steht vor einem kleinen roten Objekt , das wie ein Flugzeug aussieht . <eos> <bos>A man is standing in front of a small red object that looks like a plane .\n",
      "inputs:  <bos>Ein Hund spielt mit einem Schlauch . <eos> <bos>A dog is playing with a hose .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:16,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann und ein kleines Mädchen posieren glücklich vor ihrem Einkaufswagen im Supermarkt . <eos> <bos>A man and a little girl happily posing in front of their cart in a supermarket .\n",
      "inputs:  <bos>Ein weißer Hund ist kurz davor , ein gelbes Hundespielzeug zu fangen . <eos> <bos>A white dog is about to catch a yellow dog toy .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:16,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Kerl in einem grünen Hemd , dessen Hand einen Teil seines Gesichts bedeckt , in einer Nische im Restaurant . <eos> <bos>Guy in green shirt with hand covering part of his face in restaurant booth .\n",
      "inputs:  <bos>Ein schwarz - weißer Hund spring zu einem gelben Spielzeug hoch . <eos> <bos>A black and white dog jumps up towards a yellow toy .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:16,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei Wanderer machen bei einem Stückchen Schnee Pause . <eos> <bos>Two hikers resting by a patch of snow .\n",
      "inputs:  <bos>Ein Mann führt seine neue hölzerne Kreation vor . <eos> <bos>A man showing off his new wooden creation .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [00:17,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein älterer Vater und sein erwachsener Sohn bereiten sich auf einen Camping - Ausflug in der Wildnis vor . <eos> <bos>A elderly father and his grown son are preparing for a camping trip in the wild .\n",
      "inputs:  <bos>Ein Reisender mit Bart in einem roten Hemd , der in einem Auto sitzt und eine Karte liest . <eos> <bos>A bearded traveler in a red shirt sitting in a car and reading a map .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:17,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Junge winkt einer Ente im Wasser zu , umgeben von einer Grünanlage . <eos> <bos>A young boy waves his hand at the duck in the water surrounded by a green park .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [00:17,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Paar sitzt mit Baby und Sportwagen im Gras . <eos> <bos>A couple sit on the grass with a baby and stroller .\n",
      "inputs:  <bos>Ein paar Männer stehen vor einem Gebäude neben einem parkenden Auto . <eos> <bos>Some men standing in front of a building next to a parked car .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:18,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Der schwarze Hund rennt durch das Wasser . <eos> <bos>The black dog runs through the water .\n",
      "inputs:  <bos>Ein Mann bohrt durch das gefrorene Eis eines Teichs . <eos> <bos>A man is drilling through the frozen ice of a pond .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:18,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei große lohfarbene Hunde spielen an einem sandigen Strand . <eos> <bos>Two large tan dogs play along a sandy beach .\n",
      "inputs:  <bos>Eine Person in blau und rot , die mit zwei Pickeln eisklettert . <eos> <bos>A person in blue and red ice climbing with two picks .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [00:18,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Drei Personen , die auf einem Pfad in einer Wiese gehen . <eos> <bos>Three people walking on a path in a meadow .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:19,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Mann in Schwarz schaufelt Schnee auf die Straße und ignoriert dabei die öffentliche Sicherheit . <eos> <bos>A man in black attire shovels snow into the street , disregarding all public safety .\n",
      "inputs:  <bos>Ein Paar steht hinter seiner Hochzeitstorte . <eos> <bos>A couple stands behind their wedding cake .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86it [00:19,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein nasser schwarzer Hund trägt ein grünes Spielzeug durch das Gras . <eos> <bos>A wet black dog is carrying a green toy through the grass .\n",
      "inputs:  <bos>Dorfbewohner verkaufen ihre Ernte auf dem Markt . <eos> <bos>Villagers selling their crops at the market .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:20,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>In einem vollen Konzert nähert sich ein Mann dem Hauptsänger , der ein gelbes Hemd trägt . <eos> <bos>In a crowded concert a man in white is approaching the main singer who is wearing a yellow shirt .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89it [00:20,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Ein Junge springt auf seinem Skateboard , und eine Menschenmenge sieht zu . <eos> <bos>A boy jumps on his skateboard while a crowd watches\n",
      "inputs:  <bos>Ein Mann und ein Baby befinden sich in einem gelben Kajak auf dem Wasser . <eos> <bos>A man and a baby are in a yellow kayak on water .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:21,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei Personen sitzen auf einer Bank , und eine Frau steht neben ihnen . <eos> <bos>Two people are sitting on a bench , and one women is standing by them .\n",
      "inputs:  <bos>Eine Baustelle auf einer Straße mit drei arbeitenden Männern . <eos> <bos>A construction site on a street with three men working .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [00:21,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei Männer sitzen auf einer Bank und reden , im Hintergrund eine Reklamefläche mit Werbung für Brillen . <eos> <bos>Two men sitting on a bench talking , with a billboard advertisement for glasses in the background .\n",
      "inputs:  <bos>Eine Gruppe Jugendlicher geht die Straße entlang und schwenkt Fahnen , die das Farbspektrum zeigen . <eos> <bos>A group of youths march down the street waving flags showing the color spectrum .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [00:21,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Drei alte Männer sehen einem anderen Mann zu , wie er Fisch zubereitet . <eos> <bos>Three old men are watching another man prepare fish .\n",
      "inputs:  <bos>Eine Frau einem einem weißen Pullunder mit einem grünen , wallenden Rock ein Lied singend auf der Bühne . <eos> <bos>A woman in a white tank top with a green flowing skirt , on stage singing a song .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:22,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Zwei Männer und zwei Frauen , die auf Treppenstufen im Freien sitzen . <eos> <bos>Two men and two women sitting on steps outdoors .\n",
      "inputs:  <bos>Ein brauner und ein schwarzer Labrador im Freien , wobei der schwarze Labrador ein Spielzeug in seinem Maul hat . <eos> <bos>A brown and black lab are outside and the black lab is catching a toy in its mouth .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:22,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  <bos>Junger männlicher Hockey - Goalie in roter Jacke duckt sich mit Stock beim Tor . <eos> <bos>Hockey goalie boy in red jacket crouches by goal , with stick .\n",
      "Trained on 100 datapts\n",
      "Epoch: 1, Train loss: 0.027, Val loss: 0.000, Epoch time = 25.822s\n"
     ]
    }
   ],
   "source": [
    "# de_tokenizer.get_vocab_size()\n",
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer)#, train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = 0#evaluate(model)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'oct2+1')\n",
    "# model = torch.load('oct2+1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, mask = torch.ones((32, 8, 23, 64)), torch.ones((32, 8, 24, 64)), torch.ones((23, 24))\n",
    "attn_scores = torch.softmax(\n",
    "            einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(2) + mask,#torch.FloatTensor(self.d_hidden//8)),\n",
    "            dim=-1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 23, 24])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(einops.einsum(q, k, 'b h T_out d_h, b h T_in d_h -> b h T_out T_in')/math.sqrt(2)).shape# + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1573, -2.0253, -1.4835,  ..., -0.8829, -0.1583, -1.5284]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1573, -2.0253, -1.4835,  ..., -0.8829, -0.1583, -1.5284],\n",
      "         [-1.1587, -1.4320, -1.3938,  ..., -0.6338, -0.1273, -1.6783]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1573, -2.0253, -1.4835,  ..., -0.8829, -0.1583, -1.5284],\n",
      "         [-1.1587, -1.4320, -1.3938,  ..., -0.6338, -0.1273, -1.6783],\n",
      "         [-1.6576, -1.1608, -1.0758,  ..., -1.1079, -0.1805, -2.0747]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1573, -2.0253, -1.4835,  ..., -0.8829, -0.1583, -1.5284],\n",
      "         [-1.1587, -1.4320, -1.3938,  ..., -0.6338, -0.1273, -1.6783],\n",
      "         [-1.6576, -1.1608, -1.0758,  ..., -1.1079, -0.1805, -2.0747],\n",
      "         [-1.6403, -0.9788, -1.5941,  ..., -1.2258, -0.2059, -1.8604]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1573, -2.0253, -1.4835,  ..., -0.8829, -0.1583, -1.5284],\n",
      "         [-1.1587, -1.4320, -1.3938,  ..., -0.6338, -0.1273, -1.6783],\n",
      "         [-1.6576, -1.1608, -1.0758,  ..., -1.1079, -0.1805, -2.0747],\n",
      "         [-1.6403, -0.9788, -1.5941,  ..., -1.2258, -0.2059, -1.8604],\n",
      "         [-1.7102, -1.1751, -1.4040,  ..., -0.5947, -0.6634, -2.2394]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.1573, -2.0253, -1.4835,  ..., -0.8829, -0.1583, -1.5284],\n",
      "         [-1.1587, -1.4320, -1.3938,  ..., -0.6338, -0.1273, -1.6783],\n",
      "         [-1.6576, -1.1608, -1.0758,  ..., -1.1079, -0.1805, -2.0747],\n",
      "         [-1.6403, -0.9788, -1.5941,  ..., -1.2258, -0.2059, -1.8604],\n",
      "         [-1.7102, -1.1751, -1.4040,  ..., -0.5947, -0.6634, -2.2394],\n",
      "         [-1.5515, -0.6106, -1.5542,  ..., -0.8298,  0.3627, -2.1583]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_toks = [BOS_IDX] #+ list(text_transform_en('[BOS]'))\n",
    "src_toks = de_tokenizer.encode(de_data[80]).ids\n",
    "# src_toks = text_transform_en('<bos>')#torch.Tensor([   2,  313,  400,  826, 1276,    3]).long()\n",
    "model = torch.load('it_kindof_works')\n",
    "model.eval()\n",
    "toks_generated=0\n",
    "max_len=10#100\n",
    "while y_toks[-1] != EOS_IDX and toks_generated < max_len:\n",
    "    toks_generated+=1\n",
    "    out_logits = model(torch.tensor(src_toks).unsqueeze(0), torch.tensor(y_toks).unsqueeze(0), is_causal_tgt=True)\n",
    "    print(out_logits)\n",
    "    # print(out_logits[:,-1].shape, \"sfdsfhadsfhsdkjhfSDFfdf\")\n",
    "    idx_predicted = torch.argmax(out_logits[:,-1])\n",
    "    y_toks.append(idx_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2,\n",
       "  tensor(120),\n",
       "  tensor(167),\n",
       "  tensor(162),\n",
       "  tensor(101),\n",
       "  tensor(96),\n",
       "  tensor(3)],\n",
       " 'A man in a .',\n",
       " 'Two large tan dogs play along a sandy beach.')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_toks,\n",
    "en_tokenizer.decode(y_toks),#[2456]),\n",
    "en_data[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'it_doeskn_works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.zeros((2, 2, 3, 3)) + MultiHeadAttention.causal_mask(n_heads=2, mask_shape=(3,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
